{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c5f93a5-fa7c-4094-b4e9-76050ebb7b55",
   "metadata": {},
   "source": [
    "# Rerank\n",
    "本筆記本介紹如何開始使用Chroma向量儲存。\n",
    "- https://python.langchain.com/docs/integrations/document_transformers/rankllm-reranker/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4180e725-96bf-4dc8-941b-06cdaa90f463",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 安裝套件\n",
    "!uv pip install -qU \"langchain-chroma\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e607eee-2a4e-48d3-b8a8-03608b06a209",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function for printing docs\n",
    "def pretty_print_docs(docs):\n",
    "    print(\n",
    "        f\"\\n{'-' * 100}\\n\".join(\n",
    "            [f\"Document {i+1}:\\n\\n\" + d.page_content for i, d in enumerate(docs)]\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99797401-6585-45ee-82ff-67d83a1119cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter API key for NVIDIA:  ········\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\uv\\langchaing\\Lib\\site-packages\\langchain_nvidia_ai_endpoints\\_common.py:212: UserWarning: Found meta/llama-4-maverick-17b-128e-instruct in available_models, but type is unknown and inference may fail.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# llm模型設定\n",
    "# https://build.nvidia.com/deepseek-ai/deepseek-r1\n",
    "# nvapi-xxx\n",
    "import getpass\n",
    "import os\n",
    "if not os.environ.get(\"NVIDIA_API_KEY\"):\n",
    "  os.environ[\"NVIDIA_API_KEY\"] = getpass.getpass(\"Enter API key for NVIDIA: \")\n",
    "\n",
    "from langchain.chat_models import init_chat_model\n",
    "llm = init_chat_model(\"meta/llama-4-maverick-17b-128e-instruct\", model_provider=\"nvidia\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2476fdb9-bec9-4ed9-8e60-9fa4fed3275b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter API key for Voyage AI:  ········\n"
     ]
    }
   ],
   "source": [
    "# embedding and rerank 模型\n",
    "# https://jina.ai/\n",
    "# jina_xxx\n",
    "import getpass\n",
    "import os\n",
    "\n",
    "if not os.environ.get(\"JINA_API_KEY\"):\n",
    "  os.environ[\"JINA_API_KEY\"] = getpass.getpass(\"Enter API key for Voyage AI: \")\n",
    "\n",
    "from langchain_community.embeddings import JinaEmbeddings\n",
    "embeddings = JinaEmbeddings(\n",
    "    jina_api_key=os.environ[\"JINA_API_KEY\"], model_name=\"jina-embeddings-v3\"\n",
    ")\n",
    "\n",
    "\n",
    "from langchain_community.document_compressors import JinaRerank\n",
    "\n",
    "rerank = JinaRerank(model=\"jina-reranker-v2-base-multilingual\")  # 或使用 \"rerank-1\" 精準但較慢"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f9e583f-d169-4f24-a2cf-41a3dc82dc1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "\n",
    "vector_store = Chroma(\n",
    "    #collection_name=\"example_collection\",\n",
    "    embedding_function=embeddings,\n",
    "    persist_directory=\"./chroma_langchain_db30\",  # Where to save data locally, remove if not necessary\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6e4d34a-33ff-418e-80b7-366af5012bde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: 1aa3d78d-c1c4-4f8f-b9c9-f83d4d5c9884\n",
      "Document: I had chocolate chip pancakes and scrambled eggs for breakfast this morning.\n",
      "Metadata: {'source': 'tweet'}\n",
      "========================================\n",
      "ID: f5030079-91cc-4652-9243-e1910da2ae6c\n",
      "Document: The weather forecast for tomorrow is cloudy and overcast, with a high of 62 degrees.\n",
      "Metadata: {'source': 'news'}\n",
      "========================================\n",
      "ID: 13268674-6721-46a6-ae7d-b409c71f6b55\n",
      "Document: Building an exciting new project with LangChain - come check it out!\n",
      "Metadata: {'source': 'tweet'}\n",
      "========================================\n",
      "ID: 7d929b87-a1c1-4de6-9584-844f09986730\n",
      "Document: Robbers broke into the city bank and stole $1 million in cash.\n",
      "Metadata: {'source': 'news'}\n",
      "========================================\n",
      "ID: a3789186-b526-4cad-b320-dd81309ff9c7\n",
      "Document: Wow! That was an amazing movie. I can't wait to see it again.\n",
      "Metadata: {'source': 'tweet'}\n",
      "========================================\n",
      "ID: 2b69b396-2195-44ec-bd11-c23f1d8affae\n",
      "Document: Is the new iPhone worth the price? Read this review to find out.\n",
      "Metadata: {'source': 'website'}\n",
      "========================================\n",
      "ID: d93f6e7f-e17c-4953-bdba-a906d6c11afe\n",
      "Document: The top 10 soccer players in the world right now.\n",
      "Metadata: {'source': 'website'}\n",
      "========================================\n",
      "ID: bd4ff150-933c-4601-8444-7732de415660\n",
      "Document: LangGraph is the best framework for building stateful, agentic applications!\n",
      "Metadata: {'source': 'tweet'}\n",
      "========================================\n",
      "ID: d99c3215-94fb-4e33-9831-3cde708b739e\n",
      "Document: The stock market is down 500 points today due to fears of a recession.\n",
      "Metadata: {'source': 'news'}\n",
      "========================================\n",
      "ID: 2dabb0f6-8cba-4906-8bb2-f30f6e8eb952\n",
      "Document: I have a bad feeling I am going to get deleted :(\n",
      "Metadata: {'source': 'tweet'}\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "# 輸出所有儲存的 document（包括 id, page_content, metadata）\n",
    "all_data = vector_store._collection.get()\n",
    "\n",
    "# 印出每筆紀錄的內容\n",
    "for i in range(len(all_data[\"ids\"])):\n",
    "    print(f\"ID: {all_data['ids'][i]}\")\n",
    "    print(f\"Document: {all_data['documents'][i]}\")\n",
    "    print(f\"Metadata: {all_data['metadatas'][i]}\")\n",
    "    print(\"=\"*40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1f9fde18-2499-4de1-9277-515ae16d10c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='7d929b87-a1c1-4de6-9584-844f09986730', metadata={'source': 'news'}, page_content='Robbers broke into the city bank and stole $1 million in cash.'),\n",
       " Document(id='d99c3215-94fb-4e33-9831-3cde708b739e', metadata={'source': 'news'}, page_content='The stock market is down 500 points today due to fears of a recession.'),\n",
       " Document(id='f5030079-91cc-4652-9243-e1910da2ae6c', metadata={'source': 'news'}, page_content='The weather forecast for tomorrow is cloudy and overcast, with a high of 62 degrees.')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Query by turning into retriever\n",
    "\n",
    "retriever = vector_store.as_retriever(\n",
    "    search_type=\"mmr\", search_kwargs={\"k\": 5, \"fetch_k\": 10}\n",
    ")\n",
    "retriever.invoke(\"Stealing from the bank is a crime\", filter={\"source\": \"news\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "80cacb01-5fec-4c5f-a49c-a1ad2cba1698",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1:\n",
      "\n",
      "Robbers broke into the city bank and stole $1 million in cash.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 2:\n",
      "\n",
      "The stock market is down 500 points today due to fears of a recession.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 3:\n",
      "\n",
      "I have a bad feeling I am going to get deleted :(\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 4:\n",
      "\n",
      "Is the new iPhone worth the price? Read this review to find out.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 5:\n",
      "\n",
      "The weather forecast for tomorrow is cloudy and overcast, with a high of 62 degrees.\n"
     ]
    }
   ],
   "source": [
    "# Step 2: 把向量資料庫轉換為 retriever，並指定檢索參數\n",
    "retriever = vector_store.as_retriever(search_kwargs={\"k\": 5})\n",
    "query = \"RStealing from the bank is a crime\"\n",
    "docs = retriever.invoke(query)\n",
    "pretty_print_docs(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "092b1094-92c4-4d72-935c-33debe1e6735",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1:\n",
      "\n",
      "Robbers broke into the city bank and stole $1 million in cash.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 2:\n",
      "\n",
      "Is the new iPhone worth the price? Read this review to find out.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 3:\n",
      "\n",
      "The weather forecast for tomorrow is cloudy and overcast, with a high of 62 degrees.\n"
     ]
    }
   ],
   "source": [
    "query = \"Stealing from the bank is a crime\"\n",
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "rerank_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=rerank, base_retriever=retriever\n",
    ")\n",
    "\n",
    "rerank_docs = rerank_retriever.invoke(query)\n",
    "#print(rerank_docs)\n",
    "pretty_print_docs(rerank_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1e803705-14f3-4d6c-af7c-f380297db3c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'Stealing from the bank is a crime',\n",
       " 'context': [Document(metadata={'source': 'news', 'relevance_score': 0.2751297354698181}, page_content='Robbers broke into the city bank and stole $1 million in cash.'),\n",
       "  Document(metadata={'source': 'website', 'relevance_score': 0.04603390023112297}, page_content='Is the new iPhone worth the price? Read this review to find out.'),\n",
       "  Document(metadata={'source': 'news', 'relevance_score': 0.044680867344141006}, page_content='The weather forecast for tomorrow is cloudy and overcast, with a high of 62 degrees.')],\n",
       " 'answer': 'Yes, stealing from the bank is a crime, specifically known as bank robbery or theft. The robbers broke the law by stealing $1 million in cash. This act is punishable under the law.'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "\n",
    "\n",
    "system_prompt = (\n",
    "    \"Use the given context to answer the question. \"\n",
    "    \"If you don't know the answer, say you don't know. \"\n",
    "    \"Use three sentence maximum and keep the answer concise. \"\n",
    "    \"Context: {context}\"\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "question_answer_chain = create_stuff_documents_chain(llm, prompt)\n",
    "chain = create_retrieval_chain(rerank_retriever, question_answer_chain)\n",
    "query = \"Stealing from the bank is a crime\"\n",
    "chain.invoke({\"input\": query}, filter={\"source\": \"news\"})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "666b5ee4-e11f-4faf-b746-196189cbb46b",
   "metadata": {},
   "source": [
    "##   作業\n",
    "\n",
    "**使用 Rerank 提升問答系統**\n",
    "\n",
    "Notebook 中創建了一個基本的問答系統，使用 Chroma 檢索相關文檔並使用 LLM 回答問題。\n",
    "\n",
    "**作業：**\n",
    "\n",
    "1.  **擴展問答系統：**\n",
    "    * 在 notebook 的基礎上，加入 Rerank 功能，提升系統回答問題的準確性。\n",
    "2.  **選擇文檔來源：**\n",
    "    * 選擇一個適合問答系統的文檔來源，例如：\n",
    "        * 網頁文章\n",
    "        * 產品說明書\n",
    "        * 法律文件\n",
    "        * 學術論文\n",
    "    * 請在報告中說明你選擇的文檔來源及其適用情境。\n",
    "3.  **實作 Rerank：**\n",
    "    * 實作 Rerank 功能，對向量資料庫檢索到的文檔進行重新排序。\n",
    "    * 可以選擇以下 Rerank 方法：\n",
    "        * 自訂 Rerank 演算法\n",
    "    * 請在報告中說明你選擇的 Rerank 方法及其原因。\n",
    "4.  **回答使用者問題：**\n",
    "    * 系統能夠根據 Rerank 後的文檔，回答使用者提出的問題。\n",
    "\n",
    "**評估標準：**\n",
    "\n",
    "* 系統是否能夠正確回答使用者提出的問題？ (40%)\n",
    "* Rerank 是否能夠提升檢索結果的相關性？ (30%)\n",
    "* Rerank 對系統效率的影響？ (30%)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38bb80ee-64c7-404e-9493-005f8aa10aeb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
