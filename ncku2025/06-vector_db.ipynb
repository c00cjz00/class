{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c5f93a5-fa7c-4094-b4e9-76050ebb7b55",
   "metadata": {},
   "source": [
    "# Chroma\n",
    "本筆記本介紹如何開始使用Chroma向量儲存。\n",
    "- https://python.langchain.com/docs/integrations/vectorstores/chroma/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4180e725-96bf-4dc8-941b-06cdaa90f463",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 安裝套件\n",
    "!uv pip install -qU \"langchain-chroma\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99797401-6585-45ee-82ff-67d83a1119cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# llm模型設定\n",
    "# https://build.nvidia.com/deepseek-ai/deepseek-r1\n",
    "# nvapi-\n",
    "import getpass\n",
    "import os\n",
    "if not os.environ.get(\"NVIDIA_API_KEY\"):\n",
    "  os.environ[\"NVIDIA_API_KEY\"] = getpass.getpass(\"Enter API key for NVIDIA: \")\n",
    "\n",
    "from langchain.chat_models import init_chat_model\n",
    "llm = init_chat_model(\"meta/llama-4-maverick-17b-128e-instruct\", model_provider=\"nvidia\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2476fdb9-bec9-4ed9-8e60-9fa4fed3275b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://jina.ai/\n",
    "# jina_\n",
    "import getpass\n",
    "import os\n",
    "if not os.environ.get(\"JINA_API_KEY\"):\n",
    "  os.environ[\"JINA_API_KEY\"] = getpass.getpass(\"Enter API key for Voyage AI: \")\n",
    "\n",
    "from langchain_community.embeddings import JinaEmbeddings\n",
    "embeddings = JinaEmbeddings(\n",
    "    jina_api_key=os.environ[\"JINA_API_KEY\"], model_name=\"jina-embeddings-v3\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9e583f-d169-4f24-a2cf-41a3dc82dc1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "\n",
    "vector_store = Chroma(\n",
    "    #collection_name=\"example_collection\",\n",
    "    embedding_function=embeddings,\n",
    "    persist_directory=\"./chroma_langchain_db31\",  # Where to save data locally, remove if not necessary\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8666585-2128-491f-bfad-3e863b3fb9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from uuid import uuid4\n",
    "\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "document_1 = Document(\n",
    "    page_content=\"I had chocolate chip pancakes and scrambled eggs for breakfast this morning.\",\n",
    "    metadata={\"source\": \"tweet\"},\n",
    "    id=1,\n",
    ")\n",
    "\n",
    "document_2 = Document(\n",
    "    page_content=\"The weather forecast for tomorrow is cloudy and overcast, with a high of 62 degrees.\",\n",
    "    metadata={\"source\": \"news\"},\n",
    "    id=2,\n",
    ")\n",
    "\n",
    "document_3 = Document(\n",
    "    page_content=\"Building an exciting new project with LangChain - come check it out!\",\n",
    "    metadata={\"source\": \"tweet\"},\n",
    "    id=3,\n",
    ")\n",
    "\n",
    "document_4 = Document(\n",
    "    page_content=\"Robbers broke into the city bank and stole $1 million in cash.\",\n",
    "    metadata={\"source\": \"news\"},\n",
    "    id=4,\n",
    ")\n",
    "\n",
    "document_5 = Document(\n",
    "    page_content=\"Wow! That was an amazing movie. I can't wait to see it again.\",\n",
    "    metadata={\"source\": \"tweet\"},\n",
    "    id=5,\n",
    ")\n",
    "\n",
    "document_6 = Document(\n",
    "    page_content=\"Is the new iPhone worth the price? Read this review to find out.\",\n",
    "    metadata={\"source\": \"website\"},\n",
    "    id=6,\n",
    ")\n",
    "\n",
    "document_7 = Document(\n",
    "    page_content=\"The top 10 soccer players in the world right now.\",\n",
    "    metadata={\"source\": \"website\"},\n",
    "    id=7,\n",
    ")\n",
    "\n",
    "document_8 = Document(\n",
    "    page_content=\"LangGraph is the best framework for building stateful, agentic applications!\",\n",
    "    metadata={\"source\": \"tweet\"},\n",
    "    id=8,\n",
    ")\n",
    "\n",
    "document_9 = Document(\n",
    "    page_content=\"The stock market is down 500 points today due to fears of a recession.\",\n",
    "    metadata={\"source\": \"news\"},\n",
    "    id=9,\n",
    ")\n",
    "\n",
    "document_10 = Document(\n",
    "    page_content=\"I have a bad feeling I am going to get deleted :(\",\n",
    "    metadata={\"source\": \"tweet\"},\n",
    "    id=10,\n",
    ")\n",
    "\n",
    "documents = [\n",
    "    document_1,\n",
    "    document_2,\n",
    "    document_3,\n",
    "    document_4,\n",
    "    document_5,\n",
    "    document_6,\n",
    "    document_7,\n",
    "    document_8,\n",
    "    document_9,\n",
    "    document_10,\n",
    "]\n",
    "uuids = [str(uuid4()) for _ in range(len(documents))]\n",
    "\n",
    "vector_store.add_documents(documents=documents, ids=uuids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e4d34a-33ff-418e-80b7-366af5012bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 輸出所有儲存的 document（包括 id, page_content, metadata）\n",
    "all_data = vector_store._collection.get()\n",
    "\n",
    "# 印出每筆紀錄的內容\n",
    "for i in range(len(all_data[\"ids\"])):\n",
    "    print(f\"ID: {all_data['ids'][i]}\")\n",
    "    print(f\"Document: {all_data['documents'][i]}\")\n",
    "    print(f\"Metadata: {all_data['metadatas'][i]}\")\n",
    "    print(\"=\"*40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453dda68-fe7f-48c9-a41d-683ce9c8ac7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 更新\n",
    "updated_document_1 = Document(\n",
    "    page_content=\"I had chocolate chip pancakes and fried eggs for breakfast this morning.\",\n",
    "    metadata={\"source\": \"tweet2\"},\n",
    "    id=1,\n",
    ")\n",
    "\n",
    "vector_store.update_document(document_id=\"d149b42a-724d-44b8-9464-aa9d79bc69a8\", document=updated_document_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee00e61b-3331-46be-8e52-a570c1f43205",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 刪除\n",
    "vector_store.delete(ids=[\n",
    "    \"d149b42a-724d-44b8-9464-aa9d79bc69a8\",\n",
    "    \"5bdc786d-7737-43a6-aa42-4f80320de6bd\"\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853ee386-d6e3-41ac-a9c6-f2e85e7b24a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 搜尋一 cosine distance\n",
    "results = vector_store.similarity_search(\n",
    "    \"LangChain provides abstractions to make working with LLMs easy\",\n",
    "    k=3,\n",
    "    filter={\"source\": \"tweet\"},\n",
    ")\n",
    "for res in results:\n",
    "    print(f\"* {res.page_content} [{res.metadata}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f30d193-5ca0-4f42-bc34-821b271bf819",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 搜尋二 cosine distance\n",
    "results = vector_store.similarity_search_with_score(\n",
    "    \"LangChain provides abstractions to make working with LLMs easy\",\n",
    "    k=3,\n",
    "    filter={\"source\": \"tweet\"},\n",
    ")\n",
    "for res, score in results:\n",
    "    print(f\"* [SIM={score:3f}] {res.page_content} [{res.metadata}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d6bfe3-aec4-44ca-8f9c-2ea276b35ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 搜尋三\n",
    "embedding_vector=embeddings.embed_query(\"I love green eggs and ham!\")\n",
    "results = vector_store.similarity_search_by_vector(\n",
    "    embedding=embedding_vector, k=1\n",
    ")\n",
    "for doc in results:\n",
    "    print(f\"* {doc.page_content} [{doc.metadata}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9fde18-2499-4de1-9277-515ae16d10c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query by turning into retriever\n",
    "\n",
    "retriever = vector_store.as_retriever(\n",
    "    search_type=\"mmr\", search_kwargs={\"k\": 2, \"fetch_k\": 5}\n",
    ")\n",
    "retriever.invoke(\"Stealing from the bank is a crime\", filter={\"source\": \"news\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd66c14b-dcb6-4af0-b05a-9eeac9889e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "\n",
    "\n",
    "system_prompt = (\n",
    "    \"Use the given context to answer the question. \"\n",
    "    \"If you don't know the answer, say you don't know. \"\n",
    "    \"Use three sentence maximum and keep the answer concise. \"\n",
    "    \"Context: {context}\"\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "question_answer_chain = create_stuff_documents_chain(llm, prompt)\n",
    "chain = create_retrieval_chain(retriever, question_answer_chain)\n",
    "query = \"Stealing from the bank is a crime\"\n",
    "chain.invoke({\"input\": query}, filter={\"source\": \"news\"})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36155ae9-9b4f-4b7e-a958-602dfdf0d738",
   "metadata": {},
   "source": [
    "## PDF FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9558ce-4179-40ae-9f73-a0603ec9da18",
   "metadata": {},
   "outputs": [],
   "source": [
    "!uv pip install -qU pypdf langchain_community\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "file_path = \"e2729e76-29a0-4be5-9eef-67809b05d6b9.pdf\"\n",
    "loader = PyPDFLoader(file_path)\n",
    "docs = loader.load()\n",
    "print(f\"Total characters: {len(docs[2].page_content)}\")\n",
    "print(docs[2].page_content[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54fc2fb6-d91f-4488-8b83-1ded010be3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,  # chunk size (characters)\n",
    "    chunk_overlap=100,  # chunk overlap (characters)\n",
    "    add_start_index=True,  # track index in original document\n",
    ")\n",
    "all_splits = text_splitter.split_documents(docs)\n",
    "\n",
    "print(f\"Split blog post into {len(all_splits)} sub-documents.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff39d9e-07b5-4404-8af9-66e2e5939bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_ids = vector_store.add_documents(documents=all_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1808fdb2-acc4-499d-8f34-b4d3cbb9c1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 輸出所有儲存的 document（包括 id, page_content, metadata）\n",
    "all_data = vector_store._collection.get()\n",
    "\n",
    "# 印出每筆紀錄的內容\n",
    "for i in range(len(all_data[\"ids\"])):\n",
    "    print(f\"ID: {all_data['ids'][i]}\")\n",
    "    print(f\"Document: {all_data['documents'][i]}\")\n",
    "    print(f\"Metadata: {all_data['metadatas'][i]}\")\n",
    "    print(\"=\"*40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "666b5ee4-e11f-4faf-b746-196189cbb46b",
   "metadata": {},
   "source": [
    "##   作業\n",
    "\n",
    "**將 Chroma 與 LLM 結合**\n",
    "\n",
    "Chroma 可以與 LLM 結合，創建更強大的應用程式。\n",
    "\n",
    "**作業：**\n",
    "\n",
    "1.  **設計一個問答系統：**\n",
    "    * 該系統使用 Chroma 或其他向量資料庫 (可選擇) 來檢索相關文檔，然後使用 LLM 來回答用戶的問題。\n",
    "2.  **選擇文檔來源：**\n",
    "    * 選擇一個適合問答系統的文檔來源，例如：\n",
    "        * 網頁文章\n",
    "        * 產品說明書\n",
    "        * 法律文件\n",
    "        * 學術論文\n",
    "    * 請在報告中說明你選擇的文檔來源及其適用情境。\n",
    "3.  **實作向量資料庫操作：**\n",
    "    * 實作以下向量資料庫操作：\n",
    "        * **新增文檔：** 將選擇的文檔轉換為 embedding 並存入向量資料庫。\n",
    "        * **相似度搜尋：** 根據使用者查詢，從向量資料庫中檢索相關文檔。\n",
    "        * **結果排序：** 根據相關性對檢索結果進行排序。\n",
    "4.  **回答使用者問題：**\n",
    "    * 系統能夠根據檢索到的文檔，回答使用者提出的問題。\n",
    "\n",
    "**評估標準：**\n",
    "\n",
    "* 系統是否能夠正確回答使用者提出的問題？ (50%)\n",
    "* 系統是否能夠找到所有相關的文檔？ (50%)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38bb80ee-64c7-404e-9493-005f8aa10aeb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
